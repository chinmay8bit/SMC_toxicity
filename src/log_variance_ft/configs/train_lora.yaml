hydra:
  searchpath:
    - file://./../../mdlm/configs

defaults:
  - config  # Refers to 'config.yaml' inside 'mdlm/configs'
  - _self_

eval:
  checkpoint_path: 'kuleshov-group/mdlm-owt'

backbone: 'hf_dit'

loader: 
  eval_batch_size: 32

model:
  length: 100

training:
  ema: 0 # this disables EMA used by MDLM

finetuning:
  num_timesteps: 20
  batch_size: 32
  lr: 0.001
  num_epochs: 100
  batches_per_epoch: 5
  patience: 10
  sample_onpolicy: true
  num_samples_for_reward_estimate: 20
  reward_estimate_method: 'logmeanexp'
  timesteps_for_loss: 1
  regularization_strength: 0.001
  kl_method: 'backward'
  kl_weight: 0.05
  lora: