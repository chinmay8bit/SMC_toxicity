{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adb898a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/cp524/dev/SMC_toxicity/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">CUDA is available. Using GPU.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mCUDA is available. Using GPU.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./../../mdlm')\n",
    "sys.path.append('./../..')\n",
    "\n",
    "import os\n",
    "os.environ[\"HF_HOME\"] = \"/vol/bitbucket/cp524/hf_cache\"\n",
    "os.environ[\"TRITON_CACHE_DIR\"] = \"/vol/bitbucket/cp524/triton_cache\"\n",
    "os.environ[\"WANDB_MODE\"] = \"disabled\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import wandb\n",
    "\n",
    "from src.utils.rich_print import rich_print\n",
    "from src.toxicity_classifier.scorer import ToxicityScorer\n",
    "from src.ppl.gpt2_ppl import compute_perplexity\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    rich_print(\"[bold green]CUDA is available. Using GPU.[/bold green]\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    rich_print(\"[bold yellow]CUDA is not available. Using CPU.[/bold yellow]\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af77b3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra.core.global_hydra import GlobalHydra\n",
    "GlobalHydra.instance().clear()\n",
    "\n",
    "from hydra import initialize, compose\n",
    "from omegaconf import DictConfig\n",
    "\n",
    "initialize(\n",
    "    config_path=\"configs\",     # relative to cwd (which is src/)\n",
    "    job_name=\"notebook\",\n",
    "    version_base=None          # disable legacyâ€version checks\n",
    ")\n",
    "\n",
    "config: DictConfig = compose(config_name=\"train_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7efdafec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a new wandb run to track this script.\n",
    "run = wandb.init(\n",
    "    # Set the wandb entity where your project will be logged (generally your team name).\n",
    "    entity=\"chinmaypani42-imperial-college-london\",\n",
    "    # Set the wandb project where this run will be logged.\n",
    "    project=\"mdlm-toxicity-log-variance-finetuning\",\n",
    "    # Track hyperparameters and run metadata.\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da1c17f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mdlm import dataloader\n",
    "tokenizer = dataloader.get_tokenizer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93b37806",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at s-nlp/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "toxicity_scorer = ToxicityScorer()\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_rewards(tokens) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    takes integer tokens directly\n",
    "    \"\"\"\n",
    "    texts = tokenizer.batch_decode(tokens)\n",
    "    scores = toxicity_scorer.score_texts(texts)\n",
    "    return scores\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_rewards_scaled(tokens) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    takes integer tokens directly\n",
    "    \"\"\"\n",
    "    return compute_rewards(tokens) / config.finetuning.alpha\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_rewards_scaled(probs, num_samples, method='mean'):\n",
    "    B = probs.shape[0]\n",
    "    dist = torch.distributions.Categorical(probs=probs)\n",
    "    samples = dist.sample((num_samples,)).reshape(num_samples * B, -1) # type: ignore\n",
    "    rewards = compute_rewards_scaled(samples).reshape(num_samples, B)\n",
    "    if method == 'mean':\n",
    "        return rewards.mean(dim=0) # E[r(x)/alpha]\n",
    "    elif method == 'logmeanexp':\n",
    "        return rewards.logsumexp(dim=0) - math.log(num_samples) # log E[exp(r(x)/alpha)]\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "542f08a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.mdlm_diffusion import MDLMDiffusion\n",
    "def _load_from_checkpoint(config, tokenizer):\n",
    "    \"\"\"Load model from checkpoint\"\"\"\n",
    "    if 'hf' in config.backbone:\n",
    "        return MDLMDiffusion(config, tokenizer=tokenizer).to(device)\n",
    "\n",
    "    return MDLMDiffusion.load_from_checkpoint(\n",
    "        config.eval.checkpoint_path, tokenizer=tokenizer, config=config\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d35d87a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MDLMDiffusion(\n",
       "  (backbone): MDLM(\n",
       "    (backbone): DITBackbone(\n",
       "      (vocab_embed): EmbeddingLayer()\n",
       "      (sigma_map): TimestepEmbedder(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "          (1): SiLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (rotary_emb): Rotary()\n",
       "      (blocks): ModuleList(\n",
       "        (0-11): 12 x DDiTBlock(\n",
       "          (norm1): LayerNorm()\n",
       "          (attn_qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_out): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (norm2): LayerNorm()\n",
       "          (mlp): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='tanh')\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (adaLN_modulation): Linear(in_features=128, out_features=4608, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (output_layer): DDitFinalLayer(\n",
       "        (norm_final): LayerNorm()\n",
       "        (linear): Linear(in_features=768, out_features=50258, bias=True)\n",
       "        (adaLN_modulation): Linear(in_features=128, out_features=1536, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (softplus): Softplus(beta=1.0, threshold=20.0)\n",
       "  (train_metrics): MetricCollection(\n",
       "    (bpd): BPD()\n",
       "    (nll): NLL()\n",
       "    (ppl): Perplexity(),\n",
       "    prefix=train/\n",
       "  )\n",
       "  (valid_metrics): MetricCollection(\n",
       "    (bpd): BPD()\n",
       "    (nll): NLL()\n",
       "    (ppl): Perplexity(),\n",
       "    prefix=val/\n",
       "  )\n",
       "  (test_metrics): MetricCollection(\n",
       "    (bpd): BPD()\n",
       "    (nll): NLL()\n",
       "    (ppl): Perplexity(),\n",
       "    prefix=test/\n",
       "  )\n",
       "  (gen_ppl_metric): Perplexity()\n",
       "  (noise): LogLinearNoise()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_ref = _load_from_checkpoint(config, tokenizer)\n",
    "p_ref.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aba4c80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_phi = _load_from_checkpoint(config, tokenizer)\n",
    "q_phi.eval()\n",
    "f_psi = torch.nn.Parameter(torch.zeros(config.finetuning.num_timesteps, device=q_phi.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ef41980",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.finetuning.lora.enabled:\n",
    "    # LORA stuff\n",
    "    lora_config = LoraConfig(\n",
    "        target_modules=list(config.finetuning.lora.target_modules),\n",
    "        r=config.finetuning.lora.r,\n",
    "        lora_alpha=config.finetuning.lora.lora_alpha,\n",
    "        lora_dropout=config.finetuning.lora.lora_dropout,\n",
    "        bias=config.finetuning.lora.bias,\n",
    "    )\n",
    "    q_phi.backbone = get_peft_model(q_phi.backbone, lora_config) # type: ignore\n",
    "\n",
    "    # Extract the lora layers for optimizer\n",
    "    # get_peft_model already freezes everything except lora params\n",
    "    q_phi_lora_layers = filter(lambda p: p.requires_grad, q_phi.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f72b362e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 170,811,986, Trainable params: 1,184,768\n"
     ]
    }
   ],
   "source": [
    "def summary(model):\n",
    "    # quick print counts\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total params: {total:,}, Trainable params: {trainable:,}\") \n",
    "\n",
    "summary(q_phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb24f4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_params = list(filter(lambda p: p.requires_grad, q_phi.parameters())) + [f_psi]\n",
    "optimizer = torch.optim.AdamW(trainable_params, lr=config.finetuning.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64893b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'model_weights_final'  # keep base folder\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d/%H%M%S\")  # e.g. 20250818/004927\n",
    "model_save_dir = os.path.join(base_dir, timestamp)\n",
    "run.log({\"model_save_dir\": model_save_dir})\n",
    "\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "# Save config and metadata files\n",
    "from omegaconf import OmegaConf\n",
    "OmegaConf.save(config=config, f=f'{model_save_dir}/config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c95f843",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_trace = []\n",
    "reward_trace = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "024dbeb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/cp524/dev/SMC_toxicity/src/log_variance_ft/../../mdlm/diffusion.py:318: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(dtype=torch.float32):\n",
      "/vol/bitbucket/cp524/dev/SMC_toxicity/src/log_variance_ft/../../mdlm/models/modeling_mdlm.py:401: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(dtype=torch.bfloat16):\n",
      "/vol/bitbucket/cp524/dev/SMC_toxicity/src/log_variance_ft/../../mdlm/models/modeling_mdlm.py:147: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/vol/bitbucket/cp524/dev/SMC_toxicity/src/log_variance_ft/../../mdlm/models/modeling_mdlm.py:285: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1/5, Loss: 32761.004670619965, Reward (avg): -8.938025665283204 KL Loss: 1013.1174644231796\n",
      "Batch 2/5, Loss: 53212.31704568863, Reward (avg): -9.035257720947266 KL Loss: 933.1049040555954\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     30\u001b[39m     q_phi_zs_given_zt, q_phi_z0_given_zt = q_phi._sample_step(z_t, t, dt)\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     p_ref_zs_given_zt, p_ref_z0_given_zt = \u001b[43mp_ref\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_sample_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Estimate rewards\u001b[39;00m\n\u001b[32m     35\u001b[39m rewards = estimate_rewards_scaled(p_ref_z0_given_zt, config.finetuning.num_samples_for_reward_estimate, method=config.finetuning.reward_estimate_method)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/cp524/dev/SMC_toxicity/src/log_variance_ft/../../src/mdlm_diffusion.py:112\u001b[39m, in \u001b[36mMDLMDiffusion._sample_step\u001b[39m\u001b[34m(self, x, t, dt)\u001b[39m\n\u001b[32m    110\u001b[39m move_chance_s = move_chance_s[:, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m    111\u001b[39m unet_conditioning = sigma_t\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m log_p_x0 = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munet_conditioning\u001b[49m\u001b[43m)\u001b[49m.float()\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m move_chance_t.ndim == log_p_x0.ndim\n\u001b[32m    114\u001b[39m p_x0 = log_p_x0.softmax(dim=-\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/cp524/dev/SMC_toxicity/src/log_variance_ft/../../mdlm/diffusion.py:319\u001b[39m, in \u001b[36mDiffusion.forward\u001b[39m\u001b[34m(self, x, sigma, return_raw_logits)\u001b[39m\n\u001b[32m    317\u001b[39m sigma = \u001b[38;5;28mself\u001b[39m._process_sigma(sigma)\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.cuda.amp.autocast(dtype=torch.float32):\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m   logits = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_raw_logits:\n\u001b[32m    322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/cp524/dev/SMC_toxicity/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/cp524/dev/SMC_toxicity/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/cp524/dev/SMC_toxicity/src/log_variance_ft/../../mdlm/models/modeling_mdlm.py:440\u001b[39m, in \u001b[36mMDLM.forward\u001b[39m\u001b[34m(self, input_ids, timesteps, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    431\u001b[39m output_hidden_states = (\n\u001b[32m    432\u001b[39m   output_hidden_states\n\u001b[32m    433\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    434\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.output_hidden_states\n\u001b[32m    435\u001b[39m )\n\u001b[32m    436\u001b[39m return_dict = return_dict \\\n\u001b[32m    437\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \\\n\u001b[32m    438\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m logits, all_hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m  \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[43m  \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m  \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    445\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n\u001b[32m    446\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m modeling_outputs.MaskedLMOutput(\n\u001b[32m    447\u001b[39m     logits=logits,\n\u001b[32m    448\u001b[39m     hidden_states=all_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    449\u001b[39m     loss=\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    450\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/cp524/dev/SMC_toxicity/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/cp524/dev/SMC_toxicity/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/cp524/dev/SMC_toxicity/src/log_variance_ft/../../mdlm/models/modeling_mdlm.py:397\u001b[39m, in \u001b[36mDITBackbone.forward\u001b[39m\u001b[34m(self, indices, sigma, output_hidden_states)\u001b[39m\n\u001b[32m    395\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[32m    396\u001b[39m   all_hidden_states.append(x)\n\u001b[32m--> \u001b[39m\u001b[32m397\u001b[39m c = F.silu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msigma_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43msigma\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    399\u001b[39m rotary_cos_sin = \u001b[38;5;28mself\u001b[39m.rotary_emb(x)\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.cuda.amp.autocast(dtype=torch.bfloat16):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/cp524/dev/SMC_toxicity/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/cp524/dev/SMC_toxicity/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/cp524/dev/SMC_toxicity/src/log_variance_ft/../../mdlm/models/modeling_mdlm.py:209\u001b[39m, in \u001b[36mTimestepEmbedder.forward\u001b[39m\u001b[34m(self, t)\u001b[39m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, t):\n\u001b[32m    207\u001b[39m   t_freq = \u001b[38;5;28mself\u001b[39m.timestep_embedding(t,\n\u001b[32m    208\u001b[39m                                    \u001b[38;5;28mself\u001b[39m.frequency_embedding_size)\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m   t_emb = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_freq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    210\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m t_emb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/cp524/dev/SMC_toxicity/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/cp524/dev/SMC_toxicity/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/cp524/dev/SMC_toxicity/venv/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/cp524/dev/SMC_toxicity/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/cp524/dev/SMC_toxicity/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/cp524/dev/SMC_toxicity/venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:432\u001b[39m, in \u001b[36mSiLU.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    431\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m432\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43msilu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/cp524/dev/SMC_toxicity/venv/lib/python3.12/site-packages/torch/nn/functional.py:2380\u001b[39m, in \u001b[36msilu\u001b[39m\u001b[34m(input, inplace)\u001b[39m\n\u001b[32m   2378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   2379\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch._C._nn.silu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2380\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43msilu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "L = q_phi.config.model.length\n",
    "eps=1e-5\n",
    "timesteps = torch.linspace(1, eps, config.finetuning.num_timesteps + 1, device=q_phi.device)\n",
    "dt = (1 - eps) / config.finetuning.num_timesteps\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(config.finetuning.num_epochs):\n",
    "    wandb.log({\"epoch\": epoch+1})\n",
    "    total_epoch_loss = 0.0\n",
    "    for batch_idx in range(config.finetuning.batches_per_epoch):\n",
    "        q_phi.train()\n",
    "        \n",
    "        # Clear all grads\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        rewards_prev = None\n",
    "        log_prob_p_ref = None\n",
    "        log_prob_q_phi = None\n",
    "        total_loss_for_all_timesteps = 0.0\n",
    "        total_log_variance_loss_for_all_timesteps = 0.0\n",
    "        total_kl_loss_for_all_timesteps = 0.0\n",
    "        kl_loss = torch.tensor(0.0, device=q_phi.device)\n",
    "        \n",
    "        # Generate batch_size samples from q_phi\n",
    "        z_t = q_phi._sample_prior(config.finetuning.batch_size, L, prompt_ids=None).to(q_phi.device) # type: ignore\n",
    "        for i in range(config.finetuning.num_timesteps, 0, -1):\n",
    "            t = timesteps[config.finetuning.num_timesteps - i] * torch.ones(z_t.shape[0], 1, device=q_phi.device)\n",
    "            # Invoke pretrained and finetune models\n",
    "            with torch.enable_grad():\n",
    "                q_phi_zs_given_zt, q_phi_z0_given_zt = q_phi._sample_step(z_t, t, dt)\n",
    "            with torch.no_grad():\n",
    "                p_ref_zs_given_zt, p_ref_z0_given_zt = p_ref._sample_step(z_t, t, dt)\n",
    "                \n",
    "            # Estimate rewards\n",
    "            rewards = estimate_rewards_scaled(p_ref_z0_given_zt, config.finetuning.num_samples_for_reward_estimate, method=config.finetuning.reward_estimate_method)\n",
    "            \n",
    "            if i < config.finetuning.num_timesteps:\n",
    "                # Sanity checks\n",
    "                assert rewards is not None and rewards_prev is not None\n",
    "                assert log_prob_p_ref is not None and log_prob_q_phi is not None\n",
    "                assert log_prob_q_phi.requires_grad\n",
    "                \n",
    "                log_w = (rewards - rewards_prev) + (log_prob_p_ref - log_prob_q_phi) # Shape: (batch-size,)\n",
    "                log_variance = (log_w - f_psi[i]) ** 2\n",
    "                log_variance_loss = log_variance.mean(dim=0) # take mean across batch dimension\n",
    "                total_log_variance_loss_for_all_timesteps += log_variance_loss.item()\n",
    "                run.log({\"log_variance_loss_per_timestep\": log_variance_loss.item()})\n",
    "                \n",
    "                total_loss = log_variance_loss + kl_loss\n",
    "                total_loss_for_all_timesteps += total_loss.item()\n",
    "                run.log({\"total_loss_per_timestep\": total_loss.item()})\n",
    "                \n",
    "                # Accumulate gradients\n",
    "                total_loss.backward()\n",
    "                \n",
    "            \n",
    "            if config.finetuning.kl_method == 'forward':\n",
    "                kld_batch = torch.where(\n",
    "                    p_ref_z0_given_zt > 0,\n",
    "                    p_ref_z0_given_zt * (torch.log(p_ref_z0_given_zt) - torch.log(q_phi_z0_given_zt.clamp_min(1e-12))),\n",
    "                    torch.zeros_like(p_ref_z0_given_zt)\n",
    "                ).sum(dim=(1, 2))\n",
    "            elif config.finetuning.kl_method == 'backward':\n",
    "                kld_batch = torch.where(\n",
    "                    q_phi_z0_given_zt > 0,\n",
    "                    q_phi_z0_given_zt * (torch.log(q_phi_z0_given_zt.clamp_min(1e-12)) - torch.log(p_ref_z0_given_zt.clamp_min(1e-12))),\n",
    "                    torch.zeros_like(q_phi_z0_given_zt)\n",
    "                ).sum(dim=(1, 2))\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown KL method: {config.finetuning.kl_method}\")\n",
    "        \n",
    "            kl_loss = config.finetuning.kl_weight * kld_batch.mean(dim=0) # take mean across batch dimension\n",
    "            total_kl_loss_for_all_timesteps += kl_loss.item()\n",
    "            run.log({\"kl_loss_per_timestep\": kl_loss.item(), \"kl_div_per_timestep\": kld_batch.mean(dim=0).item()})\n",
    "            \n",
    "            \n",
    "            q_phi_dist = torch.distributions.Categorical(probs=q_phi_zs_given_zt)\n",
    "            p_ref_dist = torch.distributions.Categorical(probs=p_ref_zs_given_zt)\n",
    "            \n",
    "            if config.finetuning.sample_onpolicy:\n",
    "                z_s = q_phi_dist.sample()\n",
    "            else:\n",
    "                z_s = p_ref_dist.sample()\n",
    "                \n",
    "            log_prob_q_phi = q_phi_dist.log_prob(z_s).sum(dim=1)\n",
    "            log_prob_p_ref = p_ref_dist.log_prob(z_s).sum(dim=1)\n",
    "            \n",
    "            # Update for next step\n",
    "            z_t = z_s\n",
    "            rewards_prev = rewards\n",
    "            \n",
    "        z_0 = z_t\n",
    "        if q_phi.config.sampling.noise_removal:\n",
    "            with torch.no_grad():\n",
    "                t = timesteps[-1] * torch.ones(z_0.shape[0], 1, device=q_phi.device)\n",
    "                unet_conditioning = q_phi.noise(t)[0]\n",
    "                logits = q_phi.forward(z_0, unet_conditioning)\n",
    "                z_0 = logits[:, :, :-1].argmax(dim=-1)\n",
    "        \n",
    "        # Compute rewards\n",
    "        rewards = compute_rewards_scaled(z_0)\n",
    "        assert rewards_prev is not None and log_prob_p_ref is not None and log_prob_q_phi is not None\n",
    "        log_w = (rewards - rewards_prev) + (log_prob_p_ref - log_prob_q_phi) # Shape: (batch-size,)\n",
    "        log_variance = (log_w - f_psi[0]) ** 2\n",
    "        log_variance_loss = log_variance.mean(dim=0) # take mean across batch dimension\n",
    "        total_log_variance_loss_for_all_timesteps += log_variance_loss.item()\n",
    "        run.log({\"log_variance_loss_per_timestep\": log_variance_loss.item()})\n",
    "        \n",
    "        total_loss = log_variance_loss + kl_loss\n",
    "        total_loss_for_all_timesteps += total_loss.item()\n",
    "        run.log({\"total_loss_per_timestep\": total_loss.item()})\n",
    "        \n",
    "        # accumulate gradients\n",
    "        total_loss.backward()\n",
    "        \n",
    "        # gradients step\n",
    "        optimizer.step()\n",
    "\n",
    "        print((f\"Batch {batch_idx+1}/{config.finetuning.batches_per_epoch}, \"\n",
    "            f\"Loss: {total_loss_for_all_timesteps}, Reward (avg): {rewards.mean(dim=0).item() * config.finetuning.alpha} \"\n",
    "            f\"KL Loss: {total_kl_loss_for_all_timesteps}\"))\n",
    "        run.log({\n",
    "            \"total_loss\": total_loss_for_all_timesteps, \n",
    "            \"log_variance_loss\": total_log_variance_loss_for_all_timesteps, \n",
    "            \"kl_loss\": total_kl_loss_for_all_timesteps,\n",
    "            \"kl_div\": total_kl_loss_for_all_timesteps / config.finetuning.kl_weight,\n",
    "            \"final_reward\": rewards.mean(dim=0).item() * config.finetuning.alpha\n",
    "        })\n",
    "        total_epoch_loss += total_loss_for_all_timesteps\n",
    "    \n",
    "    q_phi.eval()\n",
    "    avg_loss = total_epoch_loss / config.finetuning.batches_per_epoch\n",
    "    run.log({\"epoch_avg_loss\": avg_loss}, step=epoch+1)\n",
    "    \n",
    "    tokens = q_phi.sample(num_steps=100)\n",
    "    avg_rewards = compute_rewards(tokens).mean().item()\n",
    "    run.log({\"epoch_rewards\": avg_rewards}, step=epoch+1)\n",
    "    \n",
    "    # perplexity\n",
    "    texts = tokenizer.batch_decode(tokens)\n",
    "    ppl, total_ppl = compute_perplexity(\n",
    "        generations=[{\n",
    "            \"context\": \"\",\n",
    "            \"generations\": texts,\n",
    "        }],\n",
    "        device=device,\n",
    "    )\n",
    "    run.log({\"epoch_ppl\": ppl, \"epoch_total_ppl\": total_ppl}, step=epoch+1)\n",
    "     # Create a wandb Table\n",
    "    table = wandb.Table(columns=[\"Prompt\", \"Generated\"])\n",
    "    for prompt, gen in zip([\"\"]*len(texts), texts):\n",
    "        table.add_data(prompt, gen)\n",
    "    # Log the whole table for this epoch\n",
    "    wandb.log({f\"epoch_samples\": table}, step=epoch+1)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{config.finetuning.num_epochs},  Loss (avg): {avg_loss}, Reward: {avg_rewards}, PPL: {ppl}/{total_ppl}\")\n",
    "    \n",
    "    ckpt_path = f'{model_save_dir}/ckpt_{epoch+1}'\n",
    "    if config.finetuning.lora.enabled:\n",
    "        q_phi.backbone.save_pretrained(f\"{ckpt_path}/lora\")\n",
    "    else:\n",
    "        torch.save(q_phi.state_dict(), f\"{ckpt_path}/model.pth\")\n",
    "    # Save f_psi\n",
    "    torch.save(f_psi, f\"{ckpt_path}/f_psi.pth\")\n",
    "    # Save optimizer state\n",
    "    torch.save(optimizer.state_dict(), f\"{ckpt_path}/optimizer.pth\")\n",
    "    run.log({\"ckpt_path\": ckpt_path}, step=epoch+1)\n",
    "\n",
    "    loss_trace.append(avg_loss)\n",
    "    reward_trace.append(avg_rewards)\n",
    "        \n",
    "    # If BOTH loss and reward stop imporving, then stop training\n",
    "    if (\n",
    "        min(loss_trace) < min(loss_trace[-config.finetuning.patience:]) and \n",
    "        max(reward_trace) > max(reward_trace[-config.finetuning.patience:])\n",
    "    ):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39f005e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
